{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution for Textbook Contents\n",
    "> A notebook for getting data from official sources and unzipping them to machine readable formats\n",
    "\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [jupyter]\n",
    "- author: Nirant Kasliwal and Meghana Bhange\n",
    "<!-- - image: images/chart-preview.png -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "!pip install requests\n",
    "!pip install pydantic\n",
    "!pip install tqdm\n",
    "!pip install pdfminer.six\n",
    "!pip uninstall spacy \n",
    "!pip uninstall neuralcoref\n",
    "!pip install spacy==2.1.0 \n",
    "!pip install neuralcoref --no-binary neuralcoref\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_input\n",
    "import json\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import neuralcoref\n",
    "import spacy\n",
    "from textbook import Book, Chapter\n",
    "from textbookutils import pdf_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.pdfls = lambda x: [x for x in list(x.iterdir()) if x.suffix == \".pdf\"]\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get List of Books and Download Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "sheet_name = \"History\"\n",
    "books_list = (\n",
    "    f\"https://api.steinhq.com/v1/storages/5fd49704f62b6004b3eb63a3/{sheet_name}\"\n",
    ")\n",
    "r = requests.get(books_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-hide\n",
    "ncert_history_books = [Book(**x) for x in json.loads(r.text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Extract all Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse-show\n",
    "for book in tqdm(ncert_history_books):\n",
    "    book.download(\"../data/raw\")\n",
    "    book.unzip(\"../data/extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_book = ncert_history_books[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = []\n",
    "for folder in single_book.extract_to_path.ls():\n",
    "    pdf_files.extend(folder.pdfls())\n",
    "pdf_files.sort()\n",
    "pdf_files = [\n",
    "    file for file in pdf_files if file.stem[-2:].isdigit()\n",
    "]  # keep the chapter files, nothing else\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NeuralCorefernce By Huggingface and Spacy\n",
    "\n",
    "- To use the NeuralCoreference module, the one condition at the time of writing this notebook is that it is currently only functional on spacy 2.1.0. \n",
    "- More information on NerualCoreference is [here](https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30)\n",
    "\n",
    "## Using NeuralCoref\n",
    "\n",
    "NeuralCoref will resolve the coreferences and annotate them as [extension attributes](https://spacy.io/usage/processing-pipelines#custom-components-extensions) in the spaCy `Doc`,  `Span` and `Token` objects under the `._.` dictionary.\n",
    "\n",
    "Here is the list of the annotations:\n",
    "\n",
    "|  Attribute                |  Type              |  Description\n",
    "|---------------------------|--------------------|-----------------------------------------------------\n",
    "|`doc._.has_coref`          |boolean             |Has any coreference has been resolved in the Doc\n",
    "|`doc._.coref_clusters`     |list of `Cluster`   |All the clusters of corefering mentions in the doc\n",
    "|`doc._.coref_resolved`     |unicode             |Unicode representation of the doc where each corefering mention is replaced by the main mention in the associated cluster.\n",
    "|`doc._.coref_scores`       |Dict of Dict        |Scores of the coreference resolution between mentions.\n",
    "|`span._.is_coref`          |boolean             |Whether the span has at least one corefering mention\n",
    "|`span._.coref_cluster`     |`Cluster`           |Cluster of mentions that corefer with the span\n",
    "|`span._.coref_scores`      |Dict                |Scores of the coreference resolution of & span with other mentions (if applicable).\n",
    "|`token._.in_coref`         |boolean             |Whether the token is inside at least one corefering mention\n",
    "|`token._.coref_clusters`   |list of `Cluster`   |All the clusters of corefering mentions that contains the token\n",
    "\n",
    "A `Cluster` is a cluster of coreferring mentions which has 3 attributes and a few methods to simplify the navigation inside a cluster:\n",
    "\n",
    "|  Attribute or method   |  Type / Return type |  Description\n",
    "|------------------------|---------------------|-----------------------------------------------------\n",
    "|`i`                     |int                  |Index of the cluster in the Doc\n",
    "|`main`                  |`Span`               |Span of the most representative mention in the cluster\n",
    "|`mentions`              |list of `Span`       |List of all the mentions in the cluster\n",
    "|`__getitem__`           |return `Span`        |Access a mention in the cluster\n",
    "|`__iter__`              |yields `Span`        |Iterate over mentions in the cluster\n",
    "|`__len__`               |return int           |Number of mentions in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the coreferece for each pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreferce_mapping_for_each_pdf = {}\n",
    "for file in tqdm(pdf_files):\n",
    "    output_io_wrapper = StringIO()\n",
    "    plain_text = pdf_to_text(file, output_io_wrapper)\n",
    "    doc = nlp(plain_text)\n",
    "    coreferce_mapping_for_each_pdf[file] = {\n",
    "        \"plain_text\": plain_text,\n",
    "        \"doc\": doc,\n",
    "        \"resolved_text\": doc._.coref_resolved,\n",
    "        \"coreference_clusters\": doc._.coref_clusters,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
