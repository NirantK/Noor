{
  
    
        "post0": {
            "title": "Get Data",
            "content": "%load_ext autoreload %autoreload 2 . Path.pdfls = lambda x: [x for x in list(x.iterdir()) if x.suffix == &quot;.pdf&quot;] Path.ls = lambda x: list(x.iterdir()) . Get List of Books and Download Links . sheet_name = &quot;History&quot; books_list = ( f&quot;https://api.steinhq.com/v1/storages/5fd49704f62b6004b3eb63a3/{sheet_name}&quot; ) r = requests.get(books_list) . . ncert_history_books = [Book(**x) for x in json.loads(r.text)] . . Download and Extract all Books . for book in tqdm(ncert_history_books): book.download(&quot;../data/raw&quot;) book.unzip(&quot;../data/extract&quot;) . . single_book = ncert_history_books[0] . pdf_files = [] for folder in single_book.extract_to_path.ls(): pdf_files.extend(folder.pdfls()) pdf_files.sort() pdf_files = [ file for file in pdf_files if file.stem[-2:].isdigit() ] # keep the chapter files, nothing else pdf_files . from io import StringIO from typing import List from pdfminer.converter import TextConverter from pdfminer.layout import LAParams from pdfminer.pdfdocument import PDFDocument from pdfminer.pdfinterp import PDFPageInterpreter, PDFResourceManager from pdfminer.pdfpage import PDFPage from pdfminer.pdfparser import PDFParser def pdf_to_text(file: str, output_io_wrapper: object) -&gt; List[str]: &quot;&quot;&quot; Converts the pdf to text using pdfminer.six Using PDFParser to fetch PDF objects from a file stream. This is then passed to PDF document to cooperate with a PDF parser in order to dynamically import the data as processing goes ResourceManager facilitates reuse of shared resources such as fonts and images so that large objects are not allocated multiple times. Used line_margin=0.7 because anything below that was considering a paragraph break as a different text blob(bounding box?) &quot;&quot;&quot; with open(file, &quot;rb&quot;) as in_file: parser = PDFParser(in_file) doc = PDFDocument(parser) resource_manager = PDFResourceManager() test_converter = TextConverter( resource_manager, output_io_wrapper, laparams=LAParams(line_margin=0.7) ) interpreter = PDFPageInterpreter(resource_manager, test_converter) # Processor for the content of a PDF page for page in PDFPage.create_pages(doc): interpreter.process_page(page) return output_io_wrapper.getvalue() for file in pdf_files: &quot;&quot;&quot; output_io_wrapper is StringIO because TextConverter expect StringIOWrapper/TextIOWrapper or similar object as an input. This can be replaced by TextIOwrapper when we want to export the output directly to the file &quot;&quot;&quot; output_io_wrapper = StringIO() plain_text = pdf_to_text(file, output_io_wrapper) print(plain_text) . # ncert_history_books[1].unzip() .",
            "url": "https://nirantk.github.io/projectnoor/jupyter/2020/12/12/Get-and-Extract-Data.html",
            "relUrl": "/jupyter/2020/12/12/Get-and-Extract-Data.html",
            "date": " • Dec 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nirantk.github.io/projectnoor/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nirantk.github.io/projectnoor/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}